exp_name: 'cluster_prototype_v1_1_spconv'
#####-------------------------------------------------------------------
dataset: "nuscenes"
prototype_head: False
working_dir: "output/pretrain/nuscenes/cp/v1_1_spconv"
# if set to True, use cylindrical coordinates, otherwise use cartesian
cylindrical_coordinates: True
# size of the voxel in each dimension for cartesian coordinates,
# and in rho and z for cylindrical (angular is always 1°)
voxel_size: 0.1
batch_size: 16 # 32
#batch_size: 32 # 32
# learning rate
lr: 0.01  # 0.5 -> 2.0
sgd_momentum: 0.9
sgd_dampening: 0.1
weight_decay: 0.0001
num_epochs: 50
# used in superpixel loss only, drop points and pixels from the computation of the loss
dropout: 0.
# number of GPUs and CPU threads to use
num_gpus: 2 # 2
num_threads: 16
kernel_size: 3
model_n_out: 64
bn_momentum: 0.05
crop_size: [ 224, 416 ]
crop_ratio: [ 1.5555555555555556, 1.8888888888888888 ]
# point cloud backbone to use among "minkunet" and "voxelnet"
model_points: "voxelnet"
# which image pretraining to chose among:
# 'imagenet','obow', 'pixpro', 'moco_v1', 'moco_v2', 'swav',
# 'deepcluster_v2', 'dino', 'moco_coco'
image_weights: "moco_v2"
# which image encoder to use (only imagenet is available with resnet18)
images_encoder: "resnet50"
# which image decoder to use
# 'bilinear', 'unet', 'fpn', 'semseg', 'nnfe', 'dilation', 'ppkt'
decoder: "dilation"
# temperature parameter in the InfoNCE loss
NCE_temperature: 0.07
# number of positive matches in the InfoNCE loss
num_matches: 4096
# whether to use the true validation set or the custom parametrization set
training: "parametrize"
# transformations to apply to the clouds
transforms_clouds: [ "Rotation", "FlipAxis" ]
# transformations to apply to both the clouds and the images among:
# 'FlipHorizontal', 'DropCuboids', 'ResizedCrop'
transforms_mixed: [ "DropCuboids", "ResizedCrop", "FlipHorizontal" ]
# which losses to use (note that multiple losses will be summed)
# loss_per_scene, loss_superpixels, loss_superpixels_reduce,
# loss_superpixels_reduce_all, loss_superpixels_transforms
losses: [ "loss_superpixels_average" ]
# which kind of superpixels to use
superpixels_type: "dinov2_ade20k"
# only keep 1 in dataset_skip_step training examples (here use 100% of the data)
dataset_skip_step: 1
# path to weights to continue a previous training
resume_path: Null
##

###########################
## prototype
#num_prototypes: 16  # 256 -> 16
temperature: 0.1  # 0.07 -> 1
dim_out: 64
dim_hidden: 128  # 4096 -> 128
#prototype_weight: 0.5

num_pixel_prototype: 150 # pixel的prototype 数量
num_point_prototype: 150  # point的prototype 数量
dim_prototype: 64  # prototype的维度
cluster_interval: 5
cluster_uses_all_superpixel: False
# WARNING: DO NOT CHANGE THE FOLLOWING PARAMETERS
# ===============================================
normalize_features: True
superpixel_size: 30
